{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text 1: Vector space models\n",
    "**Internet Analytics - Lab 4**\n",
    "\n",
    "---\n",
    "\n",
    "**Group:** *N*\n",
    "\n",
    "**Names:**\n",
    "\n",
    "* *Anh Nghia Khau (223613)*\n",
    "* *Sandra Djambazovska(224638)*\n",
    "\n",
    "---\n",
    "\n",
    "#### Instructions\n",
    "\n",
    "*This is a template for part 1 of the lab. Clearly write your answers, comments and interpretations in Markodown cells. Don't forget that you can add $\\LaTeX$ equations in these cells. Feel free to add or remove any cell.*\n",
    "\n",
    "*Please properly comment your code. Code readability will be considered for grading. To avoid long cells of codes in the notebook, you can also embed long python functions and classes in a separate module. Don’t forget to hand in your module if that is the case. In multiple exercises, you are required to come up with your own method to solve various problems. Be creative and clearly motivate and explain your methods. Creativity and clarity will be considered for grading.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import math\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "from utils import load_json, load_pkl, save_json\n",
    "import operator\n",
    "\n",
    "import nltk\n",
    "from nltk import pos_tag\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize, RegexpTokenizer\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "\n",
    "courses = load_json('data/courses.txt')\n",
    "stopwords = load_pkl('data/stopwords.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4.1: Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_words(word):\n",
    "    \"\"\"Transform HelloWord into Hello Word\"\"\"\n",
    "    if (word.isupper() or word.islower()):\n",
    "        return word\n",
    "    else:\n",
    "        pos_to_cut = []\n",
    "        for i in range(1, len(word)):\n",
    "            if (word[i].isupper()):\n",
    "                pos_to_cut.append(i)\n",
    "        curr = 0\n",
    "        words = ''\n",
    "        for pos in pos_to_cut:\n",
    "            words += ' ' + word[curr: pos]\n",
    "            curr = pos\n",
    "        words += ' ' + word[curr:]\n",
    "        return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Pre-requisite to choosing indexing terms\"\"\"\n",
    "\"\"\"Combine RegularExpr (Remove the punctuation) and word_tokenize\"\"\"\n",
    "def tokenization(sentence):\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    temp = ''\n",
    "    for w in sentence.split():\n",
    "        temp += ' ' + split_words(w)   \n",
    "    temp = word_tokenize(temp)\n",
    "    new_sentence = ''\n",
    "    for grams in temp:\n",
    "        new_sentence += ' ' + grams\n",
    "\n",
    "    return  tokenizer.tokenize(new_sentence) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Remove words not important => smaller indexes and give more informative indexes\"\"\"\n",
    "def stop_words(sentence):\n",
    "    stopwords = load_pkl('data/stopwords.pkl')\n",
    "    return [x.lower() for x in sentence if x.lower() not in stopwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_wordnet_pos(treebank_tag):\n",
    "    \"\"\"Map ['NN', 'NNS', 'NNP', 'NNPS'] to NOUN.....\"\"\"\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"The goal of lemma and stemming is : reduces lexical variability \n",
    "                                      ⇒ reduces index size\"\"\"\n",
    "def lemmatization(sentence):\n",
    "    lemmatiser = WordNetLemmatizer()\n",
    "    tokens_pos = pos_tag(sentence)\n",
    "    tokens_pos = [(w,get_wordnet_pos(p)) for (w,p) in tokens_pos]\n",
    "    \n",
    "    return [lemmatiser.lemmatize(w, pos=p) for (w,p) in tokens_pos if p != None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocessing(sentence):\n",
    "    \"\"\"Tokenization\"\"\"\n",
    "    new_sentence = tokenization(sentence)\n",
    "    \"\"\"Stopwords\"\"\"\n",
    "    new_sentence = stop_words(new_sentence)\n",
    "    \"\"\"POS and Lemmatization\"\"\"\n",
    "    new_sentence = lemmatization(new_sentence)\n",
    "    \n",
    "    return new_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def frequent_words(nbOccurrences):\n",
    "    frequencies = {}\n",
    "    for course in courses:\n",
    "        for prep in preprocessing(course['description']):\n",
    "            if prep not in frequencies:\n",
    "                frequencies[prep] = 1\n",
    "            else:\n",
    "                frequencies[prep] += 1\n",
    "    sorted_frequencies = sorted(frequencies.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    blacklist = []\n",
    "    for(k, v) in sorted_frequencies:\n",
    "        if (v > nbOccurrences):\n",
    "            blacklist.append(k)\n",
    "    return blacklist, sorted_frequencies\n",
    "blacklist, sorted_frequencies = frequent_words(300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('student', 2055),\n",
       " ('method', 1810),\n",
       " ('learn', 1554),\n",
       " ('system', 1194),\n",
       " ('model', 1177),\n",
       " ('design', 983),\n",
       " ('content', 922),\n",
       " ('project', 774),\n",
       " ('course', 760),\n",
       " ('analysis', 744),\n",
       " ('lecture', 707),\n",
       " ('basic', 706),\n",
       " ('end', 679),\n",
       " ('work', 664),\n",
       " ('assessment', 655),\n",
       " ('concept', 651),\n",
       " ('exercise', 628),\n",
       " ('teach', 619),\n",
       " ('data', 605),\n",
       " ('process', 602),\n",
       " ('prerequisite', 597),\n",
       " ('application', 573),\n",
       " ('keywords', 573),\n",
       " ('outcome', 572),\n",
       " ('problem', 566),\n",
       " ('material', 562),\n",
       " ('write', 547),\n",
       " ('activity', 524),\n",
       " ('introduction', 506),\n",
       " ('theory', 505),\n",
       " ('skill', 495),\n",
       " ('presentation', 474),\n",
       " ('study', 473),\n",
       " ('report', 465),\n",
       " ('structure', 455),\n",
       " ('plan', 446),\n",
       " ('exam', 435),\n",
       " ('energy', 434),\n",
       " ('require', 433),\n",
       " ('technique', 433),\n",
       " ('evaluate', 429),\n",
       " ('base', 429),\n",
       " ('expect', 427),\n",
       " ('time', 407),\n",
       " ('transversal', 397),\n",
       " ('hour', 384),\n",
       " ('research', 379),\n",
       " ('group', 377),\n",
       " ('engineering', 375),\n",
       " ('recommend', 370),\n",
       " ('class', 368),\n",
       " ('property', 367),\n",
       " ('field', 365),\n",
       " ('information', 363),\n",
       " ('include', 363),\n",
       " ('control', 358),\n",
       " ('oral', 347),\n",
       " ('technology', 345),\n",
       " ('principle', 344),\n",
       " ('important', 336),\n",
       " ('make', 322),\n",
       " ('resource', 320),\n",
       " ('supervision', 319),\n",
       " ('present', 316),\n",
       " ('start', 316),\n",
       " ('scientific', 312),\n",
       " ('tool', 307),\n",
       " ('apply', 306),\n",
       " ('chemical', 305),\n",
       " ('assistant', 305),\n",
       " ('cell', 302),\n",
       " ('linear', 299),\n",
       " ('topic', 298),\n",
       " ('solution', 293),\n",
       " ('image', 290),\n",
       " ('case', 288),\n",
       " ('equation', 283),\n",
       " ('knowledge', 283),\n",
       " ('state', 282),\n",
       " ('semester', 276),\n",
       " ('office', 273),\n",
       " ('specific', 271),\n",
       " ('final', 270),\n",
       " ('analyze', 267),\n",
       " ('understand', 261),\n",
       " ('function', 261),\n",
       " ('chemistry', 258),\n",
       " ('source', 256),\n",
       " ('note', 256),\n",
       " ('signal', 254),\n",
       " ('practical', 251),\n",
       " ('epfl', 249),\n",
       " ('develop', 249),\n",
       " ('dynamic', 247),\n",
       " ('molecular', 246),\n",
       " ('program', 245),\n",
       " ('science', 245),\n",
       " ('session', 243),\n",
       " ('general', 241),\n",
       " ('cover', 240),\n",
       " ('level', 235),\n",
       " ('solve', 234),\n",
       " ('week', 233),\n",
       " ('assess', 233),\n",
       " ('describe', 227),\n",
       " ('physic', 226),\n",
       " ('management', 224),\n",
       " ('fundamental', 223),\n",
       " ('paper', 222),\n",
       " ('network', 218),\n",
       " ('development', 218),\n",
       " ('flow', 218),\n",
       " ('optical', 217),\n",
       " ('test', 216),\n",
       " ('cathedra', 215),\n",
       " ('physical', 212),\n",
       " ('forum', 212),\n",
       " ('performance', 211),\n",
       " ('device', 210),\n",
       " ('laboratory', 209),\n",
       " ('main', 207),\n",
       " ('computer', 206),\n",
       " ('result', 202),\n",
       " ('approach', 202),\n",
       " ('simulation', 200),\n",
       " ('methodology', 200),\n",
       " ('technical', 199),\n",
       " ('reaction', 199),\n",
       " ('set', 198),\n",
       " ('numerical', 198),\n",
       " ('biology', 197),\n",
       " ('objective', 196),\n",
       " ('circuit', 195),\n",
       " ('interaction', 193),\n",
       " ('task', 190),\n",
       " ('provide', 189),\n",
       " ('processing', 189),\n",
       " ('explain', 189),\n",
       " ('optimal', 187),\n",
       " ('part', 186),\n",
       " ('communication', 185),\n",
       " ('access', 184),\n",
       " ('power', 183),\n",
       " ('ch', 181),\n",
       " ('type', 180),\n",
       " ('discuss', 179),\n",
       " ('space', 179),\n",
       " ('goal', 178),\n",
       " ('effect', 178),\n",
       " ('discussion', 174),\n",
       " ('risk', 172),\n",
       " ('feedback', 169),\n",
       " ('team', 168),\n",
       " ('effectively', 167),\n",
       " ('optimization', 166),\n",
       " ('sensor', 166),\n",
       " ('optic', 166),\n",
       " ('theoretical', 163),\n",
       " ('probability', 162),\n",
       " ('high', 160),\n",
       " ('strategy', 159),\n",
       " ('evaluation', 158),\n",
       " ('role', 157),\n",
       " ('scale', 157),\n",
       " ('digital', 157),\n",
       " ('mechanical', 156),\n",
       " ('biological', 156),\n",
       " ('phase', 156),\n",
       " ('domain', 155),\n",
       " ('quantum', 155),\n",
       " ('experiment', 154),\n",
       " ('term', 153),\n",
       " ('focus', 150),\n",
       " ('transfer', 149),\n",
       " ('communicate', 149),\n",
       " ('architecture', 148),\n",
       " ('language', 148),\n",
       " ('laser', 147),\n",
       " ('experimental', 145),\n",
       " ('aspect', 145),\n",
       " ('choose', 144),\n",
       " ('lab', 143),\n",
       " ('real', 142),\n",
       " ('microscopy', 141),\n",
       " ('continuous', 141),\n",
       " ('identify', 140),\n",
       " ('mass', 139),\n",
       " ('component', 139),\n",
       " ('machine', 138),\n",
       " ('read', 137),\n",
       " ('ii', 137),\n",
       " ('electron', 136),\n",
       " ('protein', 136),\n",
       " ('mechanic', 135),\n",
       " ('software', 134),\n",
       " ('simple', 134),\n",
       " ('carry', 133),\n",
       " ('http', 133),\n",
       " ('context', 133),\n",
       " ('review', 132),\n",
       " ('compute', 131),\n",
       " ('electronic', 130),\n",
       " ('solid', 129),\n",
       " ('heat', 129),\n",
       " ('form', 129),\n",
       " ('stochastic', 129),\n",
       " ('market', 129),\n",
       " ('moodle', 129),\n",
       " ('element', 128),\n",
       " ('statistical', 128),\n",
       " ('implement', 127),\n",
       " ('question', 127),\n",
       " ('demonstrate', 127),\n",
       " ('organic', 127),\n",
       " ('interpret', 126),\n",
       " ('statistic', 126),\n",
       " ('critical', 126),\n",
       " ('integrate', 126),\n",
       " ('fourier', 125),\n",
       " ('advance', 125),\n",
       " ('link', 125),\n",
       " ('literature', 124),\n",
       " ('article', 123),\n",
       " ('mathematical', 123),\n",
       " ('light', 123),\n",
       " ('measurement', 122),\n",
       " ('year', 122),\n",
       " ('hand', 122),\n",
       " ('filter', 121),\n",
       " ('current', 120),\n",
       " ('algorithm', 120),\n",
       " ('environmental', 119),\n",
       " ('product', 119),\n",
       " ('human', 119),\n",
       " ('failure', 119),\n",
       " ('surface', 118),\n",
       " ('capacity', 118),\n",
       " ('action', 118),\n",
       " ('issue', 117),\n",
       " ('critique', 117),\n",
       " ('acquisition', 116),\n",
       " ('ass', 115),\n",
       " ('individual', 115),\n",
       " ('synthesis', 115),\n",
       " ('stability', 115),\n",
       " ('give', 115),\n",
       " ('potential', 114),\n",
       " ('computational', 114),\n",
       " ('magnetic', 112),\n",
       " ('example', 112),\n",
       " ('practice', 112),\n",
       " ('algebra', 112),\n",
       " ('relate', 111),\n",
       " ('innovation', 111),\n",
       " ('grade', 111),\n",
       " ('series', 111),\n",
       " ('industrial', 110),\n",
       " ('overview', 110),\n",
       " ('select', 110),\n",
       " ('modern', 110),\n",
       " ('decision', 110),\n",
       " ('measure', 110),\n",
       " ('interface', 110),\n",
       " ('find', 110),\n",
       " ('large', 109),\n",
       " ('sample', 108),\n",
       " ('introduce', 108),\n",
       " ('key', 108),\n",
       " ('participation', 108),\n",
       " ('algorithms', 107),\n",
       " ('transport', 107),\n",
       " ('polymer', 107),\n",
       " ('mechanism', 107),\n",
       " ('complete', 106),\n",
       " ('relevant', 105),\n",
       " ('homework', 105),\n",
       " ('water', 105),\n",
       " ('point', 104),\n",
       " ('differential', 104),\n",
       " ('module', 103),\n",
       " ('complex', 103),\n",
       " ('quality', 102),\n",
       " ('electrical', 102),\n",
       " ('spectroscopy', 101),\n",
       " ('micro', 100),\n",
       " ('operation', 100),\n",
       " ('parameter', 98),\n",
       " ('discipline', 98),\n",
       " ('policy', 97),\n",
       " ('number', 97),\n",
       " ('electronics', 97),\n",
       " ('distribution', 97),\n",
       " ('metal', 96),\n",
       " ('aim', 96),\n",
       " ('limit', 96),\n",
       " ('discrete', 96),\n",
       " ('equilibrium', 96),\n",
       " ('financial', 95),\n",
       " ('production', 95),\n",
       " ('attend', 95),\n",
       " ('area', 95),\n",
       " ('art', 94),\n",
       " ('propose', 94),\n",
       " ('law', 94),\n",
       " ('industry', 94),\n",
       " ('business', 93),\n",
       " ('semiconductor', 93),\n",
       " ('fluid', 93),\n",
       " ('force', 93),\n",
       " ('formulate', 93),\n",
       " ('structural', 93),\n",
       " ('day', 92),\n",
       " ('impact', 92),\n",
       " ('respond', 92),\n",
       " ('reactor', 92),\n",
       " ('challenge', 91),\n",
       " ('bibliography', 91),\n",
       " ('thermal', 91),\n",
       " ('matlab', 90),\n",
       " ('multi', 90),\n",
       " ('life', 90),\n",
       " ('treatment', 90),\n",
       " ('functional', 90),\n",
       " ('involve', 89),\n",
       " ('environment', 89),\n",
       " ('master', 88),\n",
       " ('active', 87),\n",
       " ('order', 87),\n",
       " ('noise', 86),\n",
       " ('acquire', 86),\n",
       " ('phenomenon', 85),\n",
       " ('description', 85),\n",
       " ('finite', 85),\n",
       " ('perform', 84),\n",
       " ('initial', 84),\n",
       " ('understanding', 84),\n",
       " ('molecule', 83),\n",
       " ('open', 83),\n",
       " ('continue', 83),\n",
       " ('social', 83),\n",
       " ('thinking', 83),\n",
       " ('prepare', 83),\n",
       " ('rate', 83),\n",
       " ('conversion', 82),\n",
       " ('professional', 82),\n",
       " ('culture', 82),\n",
       " ('assignment', 81),\n",
       " ('low', 81),\n",
       " ('calculus', 81),\n",
       " ('representation', 81),\n",
       " ('estimate', 81),\n",
       " ('build', 81),\n",
       " ('learning', 80),\n",
       " ('reach', 80),\n",
       " ('experience', 80),\n",
       " ('finance', 80),\n",
       " ('define', 80),\n",
       " ('recent', 79),\n",
       " ('classical', 79),\n",
       " ('ressources', 79),\n",
       " ('code', 78),\n",
       " ('chain', 78),\n",
       " ('cycle', 78),\n",
       " ('random', 78),\n",
       " ('summarize', 78),\n",
       " ('choice', 78),\n",
       " ('basis', 78),\n",
       " ('attendance', 78),\n",
       " ('notion', 78),\n",
       " ('implementation', 77),\n",
       " ('progress', 77),\n",
       " ('drug', 77),\n",
       " ('variable', 76),\n",
       " ('transmission', 76),\n",
       " ('wave', 76),\n",
       " ('thermodynamics', 76),\n",
       " ('economic', 75),\n",
       " ('bibliothèque', 75),\n",
       " ('skills', 75),\n",
       " ('memory', 75),\n",
       " ('mini', 74),\n",
       " ('factor', 74),\n",
       " ('detection', 74),\n",
       " ('handbook', 74),\n",
       " ('obtain', 74),\n",
       " ('book', 74),\n",
       " ('growth', 74),\n",
       " ('cod', 74),\n",
       " ('single', 73),\n",
       " ('kinetics', 72),\n",
       " ('manage', 72),\n",
       " ('security', 72),\n",
       " ('discus', 71),\n",
       " ('theorem', 71),\n",
       " ('collect', 71),\n",
       " ('address', 71),\n",
       " ('mode', 71),\n",
       " ('concrete', 70),\n",
       " ('tissue', 70),\n",
       " ('interest', 70),\n",
       " ('difficulty', 70),\n",
       " ('transform', 70),\n",
       " ('couple', 69),\n",
       " ('regression', 68),\n",
       " ('cellular', 68),\n",
       " ('liquid', 68),\n",
       " ('view', 68),\n",
       " ('estimation', 68),\n",
       " ('brain', 68),\n",
       " ('idea', 68),\n",
       " ('condition', 68),\n",
       " ('standard', 68),\n",
       " ('small', 68),\n",
       " ('characteristic', 67),\n",
       " ('seminar', 67),\n",
       " ('radiation', 67),\n",
       " ('participant', 67),\n",
       " ('subject', 67),\n",
       " ('change', 66),\n",
       " ('thermodynamic', 66),\n",
       " ('adapt', 66),\n",
       " ('limitation', 66),\n",
       " ('urban', 65),\n",
       " ('derive', 65),\n",
       " ('speaker', 65),\n",
       " ('propagation', 65),\n",
       " ('frequency', 65),\n",
       " ('school', 65),\n",
       " ('midterm', 65),\n",
       " ('preparation', 64),\n",
       " ('diffraction', 64),\n",
       " ('diffusion', 64),\n",
       " ('world', 64),\n",
       " ('appropriately', 64),\n",
       " ('short', 64),\n",
       " ('place', 63),\n",
       " ('geometry', 63),\n",
       " ('integration', 63),\n",
       " ('balance', 63),\n",
       " ('cancer', 63),\n",
       " ('essential', 63),\n",
       " ('disease', 62),\n",
       " ('option', 62),\n",
       " ('requirement', 62),\n",
       " ('matrix', 62),\n",
       " ('understood', 62),\n",
       " ('membrane', 62),\n",
       " ('outcomes', 61),\n",
       " ('analog', 61),\n",
       " ('cmos', 61),\n",
       " ('medium', 61),\n",
       " ('vector', 61),\n",
       " ('definition', 61),\n",
       " ('response', 61),\n",
       " ('dimensional', 60),\n",
       " ('transistor', 60),\n",
       " ('spring', 60),\n",
       " ('film', 60),\n",
       " ('firm', 60),\n",
       " ('error', 60),\n",
       " ('robot', 60),\n",
       " ('compare', 60),\n",
       " ('sense', 60),\n",
       " ('global', 60),\n",
       " ('transition', 60),\n",
       " ('computation', 60),\n",
       " ('distribute', 60),\n",
       " ('detail', 60),\n",
       " ('characterization', 60),\n",
       " ('good', 59),\n",
       " ('pressure', 59),\n",
       " ('examination', 59),\n",
       " ('waste', 59),\n",
       " ('doctoral', 59),\n",
       " ('major', 59),\n",
       " ('exercices', 59),\n",
       " ('explore', 59),\n",
       " ('search', 59),\n",
       " ('participate', 59),\n",
       " ('feature', 58),\n",
       " ('behavior', 58),\n",
       " ('speech', 58),\n",
       " ('weekly', 58),\n",
       " ('nonlinear', 58),\n",
       " ('relation', 58),\n",
       " ('programming', 58),\n",
       " ('gas', 58),\n",
       " ('background', 58),\n",
       " ('solar', 58),\n",
       " ('layer', 57),\n",
       " ('ph', 57),\n",
       " ('related', 57),\n",
       " ('assembly', 57),\n",
       " ('future', 57),\n",
       " ('generation', 57),\n",
       " ('conduct', 57),\n",
       " ('neuroscience', 57),\n",
       " ('approximation', 57),\n",
       " ('analyse', 56),\n",
       " ('rule', 56),\n",
       " ('classroom', 56),\n",
       " ('resolution', 56),\n",
       " ('supply', 56),\n",
       " ('determine', 55),\n",
       " ('building', 55),\n",
       " ('engineer', 55),\n",
       " ('particle', 55),\n",
       " ('site', 55),\n",
       " ('manner', 55),\n",
       " ('produce', 55),\n",
       " ('health', 55),\n",
       " ('regulation', 54),\n",
       " ('begin', 54),\n",
       " ('recognition', 54),\n",
       " ('transformation', 54),\n",
       " ('line', 54),\n",
       " ('generate', 54),\n",
       " ('multiple', 54),\n",
       " ('hypothesis', 54),\n",
       " ('examples', 54),\n",
       " ('visual', 54),\n",
       " ('pattern', 54),\n",
       " ('matter', 54),\n",
       " ('medicine', 53),\n",
       " ('electrochemical', 53),\n",
       " ('fiber', 53),\n",
       " ('common', 53),\n",
       " ('exchange', 53),\n",
       " ('hardware', 53),\n",
       " ('en', 53),\n",
       " ('studio', 53),\n",
       " ('operate', 53),\n",
       " ('free', 53),\n",
       " ('natural', 52),\n",
       " ('perspective', 52),\n",
       " ('section', 52),\n",
       " ('respect', 52),\n",
       " ('block', 52),\n",
       " ('public', 52),\n",
       " ('lead', 52),\n",
       " ('graph', 52),\n",
       " ('portfolio', 52),\n",
       " ('price', 52),\n",
       " ('reference', 52),\n",
       " ('storage', 52),\n",
       " ('support', 52),\n",
       " ('efficiency', 52),\n",
       " ('expression', 51),\n",
       " ('emphasis', 51),\n",
       " ('acoustic', 51),\n",
       " ('bio', 51),\n",
       " ('slide', 51),\n",
       " ('introduces', 51),\n",
       " ('pricing', 51),\n",
       " ('combine', 51),\n",
       " ('calculation', 51),\n",
       " ('illustrate', 51),\n",
       " ('integral', 51),\n",
       " ('compound', 51),\n",
       " ('construct', 51),\n",
       " ('history', 51),\n",
       " ('opportunity', 51),\n",
       " ('web', 51),\n",
       " ('iii', 50),\n",
       " ('create', 50),\n",
       " ('receive', 50),\n",
       " ('nuclear', 50),\n",
       " ('analytical', 50),\n",
       " ('formation', 50),\n",
       " ('professor', 50),\n",
       " ('wireless', 50),\n",
       " ('range', 50),\n",
       " ('fracture', 50),\n",
       " ('mathematics', 49),\n",
       " ('channel', 49),\n",
       " ('service', 49),\n",
       " ('composite', 49),\n",
       " ('map', 49),\n",
       " ('company', 49),\n",
       " ('direct', 49),\n",
       " ('stress', 49),\n",
       " ('architectural', 49),\n",
       " ('scan', 49),\n",
       " ('print', 49),\n",
       " ('ray', 49),\n",
       " ('electromagnetic', 49),\n",
       " ('spatial', 49),\n",
       " ('thin', 49),\n",
       " ('asset', 48),\n",
       " ('orient', 48),\n",
       " ('body', 48),\n",
       " ('lecturer', 48),\n",
       " ('ion', 48),\n",
       " ('contact', 48),\n",
       " ('quantitative', 48),\n",
       " ('economics', 48),\n",
       " ('boundary', 48),\n",
       " ('priority', 47),\n",
       " ('load', 47),\n",
       " ('behaviour', 47),\n",
       " ('separation', 47),\n",
       " ('characterize', 47),\n",
       " ('equivalent', 47),\n",
       " ('evolution', 46),\n",
       " ('pathway', 46),\n",
       " ('biomedical', 46),\n",
       " ('complexity', 46),\n",
       " ('assign', 46),\n",
       " ('bond', 46),\n",
       " ('nano', 46),\n",
       " ('elaborate', 46),\n",
       " ('beam', 46),\n",
       " ('underlie', 46),\n",
       " ('identification', 46),\n",
       " ('organization', 46),\n",
       " ('organize', 45),\n",
       " ('chapter', 45),\n",
       " ('motion', 45),\n",
       " ('difference', 45),\n",
       " ('spectral', 45),\n",
       " ('step', 45),\n",
       " ('classification', 45),\n",
       " ('php', 45),\n",
       " ('synthesize', 45),\n",
       " ('selection', 45),\n",
       " ('object', 44),\n",
       " ('video', 44),\n",
       " ('convergence', 44),\n",
       " ('markov', 44),\n",
       " ('framework', 44),\n",
       " ('actuator', 44),\n",
       " ('technological', 44),\n",
       " ('animal', 43),\n",
       " ('derivative', 43),\n",
       " ('chip', 43),\n",
       " ('meeting', 43),\n",
       " ('charge', 43),\n",
       " ('academic', 43),\n",
       " ('advantage', 43),\n",
       " ('close', 43),\n",
       " ('instrument', 43),\n",
       " ('grid', 43),\n",
       " ('depend', 43),\n",
       " ('corporate', 43),\n",
       " ('home', 42),\n",
       " ('emission', 42),\n",
       " ('influence', 42),\n",
       " ('responsibility', 42),\n",
       " ('unit', 42),\n",
       " ('emerge', 42),\n",
       " ('special', 42),\n",
       " ('creativity', 42),\n",
       " ('carlo', 42),\n",
       " ('absorption', 42),\n",
       " ('variety', 41),\n",
       " ('recognize', 41),\n",
       " ('relationship', 41),\n",
       " ('rf', 41),\n",
       " ('reading', 41),\n",
       " ('biochemistry', 41),\n",
       " ('predict', 41),\n",
       " ('density', 41),\n",
       " ('construction', 41),\n",
       " ('position', 41),\n",
       " ('food', 41),\n",
       " ('target', 41),\n",
       " ('converter', 41),\n",
       " ('exist', 41),\n",
       " ('cs', 41),\n",
       " ('page', 41),\n",
       " ('nature', 41),\n",
       " ('tem', 41),\n",
       " ('efficient', 41),\n",
       " ('user', 40),\n",
       " ('perception', 40),\n",
       " ('wastewater', 40),\n",
       " ('enable', 40),\n",
       " ('amplifier', 40),\n",
       " ('reliability', 40),\n",
       " ('gene', 40),\n",
       " ('interactive', 40),\n",
       " ('safety', 40),\n",
       " ('fashion', 40),\n",
       " ('variance', 40),\n",
       " ('credit', 40),\n",
       " ('list', 40),\n",
       " ('catalysis', 40),\n",
       " ('verification', 40),\n",
       " ('symmetry', 40),\n",
       " ('ceramic', 39),\n",
       " ('online', 39),\n",
       " ('show', 39),\n",
       " ('metabolism', 39),\n",
       " ('foundation', 39),\n",
       " ('mean', 39),\n",
       " ('monte', 39),\n",
       " ('workshop', 39),\n",
       " ('ability', 39),\n",
       " ('motor', 39),\n",
       " ('crystal', 39),\n",
       " ('prediction', 39),\n",
       " ('draw', 38),\n",
       " ('personal', 38),\n",
       " ('parallel', 38),\n",
       " ('external', 38),\n",
       " ('edition', 38),\n",
       " ('offer', 38),\n",
       " ('steel', 38),\n",
       " ('advanced', 38),\n",
       " ('investigate', 38),\n",
       " ('dna', 38),\n",
       " ('id', 38),\n",
       " ('empirical', 38),\n",
       " ('cost', 38),\n",
       " ('insight', 38),\n",
       " ('dimension', 38),\n",
       " ('formulation', 37),\n",
       " ('typical', 37),\n",
       " ('neural', 37),\n",
       " ('spin', 37),\n",
       " ('criterion', 37),\n",
       " ('invite', 37),\n",
       " ('stem', 37),\n",
       " ('size', 37),\n",
       " ('university', 37),\n",
       " ('snow', 37),\n",
       " ('synthetic', 37),\n",
       " ('shape', 37),\n",
       " ('plasma', 37),\n",
       " ('mobile', 36),\n",
       " ('talk', 36),\n",
       " ('visit', 36),\n",
       " ('experimentation', 36),\n",
       " ('sequence', 36),\n",
       " ('audio', 36),\n",
       " ('situation', 36),\n",
       " ('volatility', 36),\n",
       " ('vision', 36),\n",
       " ('convex', 36),\n",
       " ('constraint', 36),\n",
       " ('introductory', 36),\n",
       " ('de', 36),\n",
       " ('atomic', 36),\n",
       " ('input', 35),\n",
       " ('optimize', 35),\n",
       " ('integrated', 35),\n",
       " ('momentum', 35),\n",
       " ('post', 35),\n",
       " ('event', 35),\n",
       " ('inorganic', 35),\n",
       " ('teacher', 35),\n",
       " ('edms', 35),\n",
       " ('deep', 35),\n",
       " ('press', 35),\n",
       " ('fluorescence', 35),\n",
       " ('embed', 35),\n",
       " ('modulation', 35),\n",
       " ('mid', 35),\n",
       " ('partial', 35),\n",
       " ('detector', 35),\n",
       " ('importance', 35),\n",
       " ('bachelor', 34),\n",
       " ('probe', 34),\n",
       " ('principal', 34),\n",
       " ('microscope', 34),\n",
       " ('leadership', 34),\n",
       " ('publication', 34),\n",
       " ('trend', 34),\n",
       " ('intermediate', 34),\n",
       " ('static', 34),\n",
       " ('diagram', 34),\n",
       " ('drive', 34),\n",
       " ('privacy', 34),\n",
       " ('protocol', 34),\n",
       " ('correlation', 34),\n",
       " ('sustainable', 34),\n",
       " ('agent', 34),\n",
       " ('microbial', 33),\n",
       " ('fuel', 33),\n",
       " ('gain', 33),\n",
       " ('gaussian', 33),\n",
       " ('intend', 33),\n",
       " ('theme', 33),\n",
       " ('plant', 33),\n",
       " ('platform', 33),\n",
       " ('clinical', 33),\n",
       " ('controller', 33),\n",
       " ('historical', 33),\n",
       " ('fabrication', 33),\n",
       " ('justify', 33),\n",
       " ('scientist', 33),\n",
       " ('elementary', 33),\n",
       " ('way', 33),\n",
       " ('demand', 33),\n",
       " ('broad', 33),\n",
       " ('prof', 33),\n",
       " ('examine', 33),\n",
       " ('uncertainty', 32),\n",
       " ('logic', 32),\n",
       " ('recycle', 32),\n",
       " ('climate', 32),\n",
       " ('discovery', 32),\n",
       " ('contrast', 32),\n",
       " ('specification', 32),\n",
       " ('waveguide', 32),\n",
       " ('reduction', 32),\n",
       " ('medical', 32),\n",
       " ('take', 32),\n",
       " ('mixed', 32),\n",
       " ('consist', 32),\n",
       " ('long', 32),\n",
       " ('depth', 32),\n",
       " ('primary', 31),\n",
       " ('realization', 31),\n",
       " ('recall', 31),\n",
       " ('powder', 31),\n",
       " ('configuration', 31),\n",
       " ('visualization', 31),\n",
       " ('supervise', 31),\n",
       " ('resolve', 31),\n",
       " ('alloy', 31),\n",
       " ('iv', 31),\n",
       " ('game', 31),\n",
       " ('assume', 31),\n",
       " ('modeling', 31),\n",
       " ('cryptography', 31),\n",
       " ('people', 31),\n",
       " ('localization', 31),\n",
       " ('tumor', 31),\n",
       " ('neuron', 31),\n",
       " ('benefit', 31),\n",
       " ('documentation', 31),\n",
       " ('represent', 31),\n",
       " ('coordination', 31),\n",
       " ('satellite', 31),\n",
       " ('local', 31),\n",
       " ('deal', 31),\n",
       " ('arbitrage', 30),\n",
       " ('cross', 30),\n",
       " ('joint', 30),\n",
       " ('procedure', 30),\n",
       " ('mix', 30),\n",
       " ('argument', 30),\n",
       " ('scheme', 30),\n",
       " ('journal', 30),\n",
       " ('manufacture', 30),\n",
       " ('cognitive', 30),\n",
       " ('operational', 30),\n",
       " ('soft', 30),\n",
       " ('frame', 30),\n",
       " ('familiar', 30),\n",
       " ('calculate', 30),\n",
       " ('intellectual', 29),\n",
       " ('stage', 29),\n",
       " ('reduce', 29),\n",
       " ('english', 29),\n",
       " ('voltage', 29),\n",
       " ('strain', 29),\n",
       " ('investment', 29),\n",
       " ('seismic', 29),\n",
       " ('match', 29),\n",
       " ('algorithmic', 29),\n",
       " ('tools', 29),\n",
       " ('fall', 29),\n",
       " ('atom', 29),\n",
       " ('central', 29),\n",
       " ('receiver', 29),\n",
       " ('math', 29),\n",
       " ('receptor', 29),\n",
       " ('internal', 29),\n",
       " ('cluster', 29),\n",
       " ('fusion', 29),\n",
       " ('heterogeneous', 29),\n",
       " ('curve', 29),\n",
       " ('bioengineering', 29),\n",
       " ('kinetic', 29),\n",
       " ('band', 29),\n",
       " ('sustainability', 28),\n",
       " ('switch', 28),\n",
       " ('full', 28),\n",
       " ('atmospheric', 28),\n",
       " ('mems', 28),\n",
       " ('formal', 28),\n",
       " ('effective', 28),\n",
       " ('follow', 28),\n",
       " ('mixture', 28),\n",
       " ('locomotion', 28),\n",
       " ('trade', 28),\n",
       " ('vhdl', 28),\n",
       " ('stream', 28),\n",
       " ('hydraulic', 28),\n",
       " ('therapeutic', 28),\n",
       " ('modification', 28),\n",
       " ('format', 28),\n",
       " ('strategic', 28),\n",
       " ('c', 28),\n",
       " ('spectrometry', 28),\n",
       " ('infrastructure', 28),\n",
       " ('establish', 28),\n",
       " ('manufacturing', 28),\n",
       " ('valuation', 28),\n",
       " ('demonstration', 28),\n",
       " ('host', 28),\n",
       " ('hybrid', 27),\n",
       " ('volume', 27),\n",
       " ('document', 27),\n",
       " ('sketch', 27),\n",
       " ('interpretation', 27),\n",
       " ('independent', 27),\n",
       " ('regular', 27),\n",
       " ('maximum', 27),\n",
       " ('database', 27),\n",
       " ('resonance', 27),\n",
       " ('sv', 27),\n",
       " ('mandatory', 27),\n",
       " ('tomography', 27),\n",
       " ('smart', 27),\n",
       " ('robotics', 27),\n",
       " ('generalize', 27),\n",
       " ('piezoelectric', 27),\n",
       " ('air', 27),\n",
       " ('big', 27),\n",
       " ('room', 27),\n",
       " ('concepts', 27),\n",
       " ('minute', 26),\n",
       " ('put', 26),\n",
       " ('capital', 26),\n",
       " ('electric', 26),\n",
       " ('date', 26),\n",
       " ('original', 26),\n",
       " ('answer', 26),\n",
       " ('metabolic', 26),\n",
       " ('ideal', 26),\n",
       " ('fix', 26),\n",
       " ('microwave', 26),\n",
       " ('functioning', 26),\n",
       " ('profession', 26),\n",
       " ('renewable', 26),\n",
       " ('wet', 26),\n",
       " ('composition', 26),\n",
       " ('total', 26),\n",
       " ('conclusion', 26),\n",
       " ('path', 26),\n",
       " ('graphic', 26),\n",
       " ('springer', 26),\n",
       " ('competition', 26),\n",
       " ('adaptive', 26),\n",
       " ('screen', 26),\n",
       " ('display', 26),\n",
       " ('sector', 26),\n",
       " ('critically', 25),\n",
       " ('dependent', 25),\n",
       " ('account', 25),\n",
       " ('architectures', 25),\n",
       " ('ethical', 25),\n",
       " ('improve', 25),\n",
       " ('passive', 25),\n",
       " ('today', 25),\n",
       " ('mem', 25),\n",
       " ('temperature', 25),\n",
       " ('loop', 25),\n",
       " ('determination', 25),\n",
       " ('core', 25),\n",
       " ('period', 25),\n",
       " ('conceptual', 25),\n",
       " ('min', 25),\n",
       " ('spectrum', 25),\n",
       " ('guide', 25),\n",
       " ('prove', 25),\n",
       " ('gradient', 25),\n",
       " ('city', 25),\n",
       " ('think', 25),\n",
       " ('dielectric', 25),\n",
       " ('dispersion', 25),\n",
       " ('addition', 25),\n",
       " ('website', 25),\n",
       " ('wide', 25),\n",
       " ('cultural', 25),\n",
       " ('cut', 25),\n",
       " ('confocal', 25),\n",
       " ('wearable', 25),\n",
       " ('parametric', 25),\n",
       " ('ee', 24),\n",
       " ('photonic', 24),\n",
       " ('ip', 24),\n",
       " ('combination', 24),\n",
       " ('maxwell', 24),\n",
       " ('organise', 24),\n",
       " ('plasticity', 24),\n",
       " ('compose', 24),\n",
       " ('validation', 24),\n",
       " ('reason', 24),\n",
       " ('lifecycle', 24),\n",
       " ('metric', 24),\n",
       " ('algebraic', 24),\n",
       " ('operator', 24),\n",
       " ('processor', 24),\n",
       " ('implication', 24),\n",
       " ('assay', 24),\n",
       " ('interdisciplinary', 24),\n",
       " ...]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Frequency of words\"\"\"\n",
    "sorted_frequencies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4.2: Term-document matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Read data and return a term-frequency matrix\"\"\"\n",
    "\"\"\"Weighting scheme for term t in doc d: \n",
    "   \n",
    "   TF(t,d) =  # occurs of t in d / max {# occurs of t'} for all terms t' in d\"\"\"\n",
    "\n",
    "\n",
    "def load_data(path):\n",
    "    \"\"\"Mapping from 'term' to 'row indice'\"\"\"\n",
    "    term_indices = {}\n",
    "    \"\"\"Mapping from 'row indice' to 'term'\"\"\"\n",
    "    indices_term = {}\n",
    "    \"\"\"Mapping from 'courseID' to 'col indice'\"\"\"\n",
    "    doc_indices = {}\n",
    "    \"\"\"Mapping from 'courseID' to 'course name'\"\"\"\n",
    "    doc_names = {}\n",
    "    \n",
    "    values = []\n",
    "    rows = []\n",
    "    columns = []\n",
    "    courses = load_json(path)\n",
    "    terms_count = 0\n",
    "    docs_count = 0\n",
    "    \n",
    "    blacklist, frequencies = frequent_words(300)\n",
    "    \n",
    "    for course in courses:\n",
    "        id_  = course['courseId']\n",
    "        name = course['name']\n",
    "        description = course['description']\n",
    "        doc_indices[id_] = docs_count\n",
    "        doc_names[id_] = name\n",
    "\n",
    "        processed = preprocessing(description)\n",
    "        for term in processed:\n",
    "            \"\"\"Remove 1-gram and 2-grams\"\"\"\n",
    "            if(len(term) <= 2):\n",
    "                continue\n",
    "            \"\"\"Remove very frequent words nb occurrences > 300\"\"\"\n",
    "            if (term in blacklist):\n",
    "                continue\n",
    "            if term not in term_indices:\n",
    "                term_indices[term] = terms_count\n",
    "                indices_term[terms_count] = term\n",
    "                terms_count += 1\n",
    "            \"\"\"Append a value to matrix(row, col)\"\"\"\n",
    "            values.append(1.0)\n",
    "            rows.append(term_indices[term])\n",
    "            columns.append(docs_count)\n",
    "        \"\"\"Go to another doc\"\"\"\n",
    "        docs_count += 1\n",
    "    \"\"\"Create csr matrix\"\"\"\n",
    "    tf_matrix = csr_matrix((values, (rows, columns)), shape=(terms_count, docs_count))\n",
    "    \"\"\"Transforme to TF matrix\"\"\"\n",
    "    for col in range(docs_count):\n",
    "        tf_matrix[:,col] /= np.max(tf_matrix.getcol(col))\n",
    "        \n",
    "    return tf_matrix, term_indices, indices_term, doc_indices, doc_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Inverse Docement Frequency IDF(t,D): log(# documents/ # documents contain term t)\"\"\"\n",
    "\"\"\"TF_IDF = TF(t,d)*IDF(t,D)\"\"\"\n",
    "def tf_idf(tf_matrix, doc_indices, term_indices):\n",
    "    nbDocs = len(doc_indices)\n",
    "    nbTerms= len(term_indices)\n",
    "    tfidf_matrix = tf_matrix.copy()\n",
    "    for i in range(nbTerms):\n",
    "        tfidf_matrix[i,:] *= math.log(nbDocs/tfidf_matrix.getrow(i).nnz)\n",
    "    return tfidf_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Store result for the rest of the lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_sparse_csr(filename,array):\n",
    "    np.savez(filename,data = array.data ,indices=array.indices,\n",
    "             indptr =array.indptr, shape=array.shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def store_result():\n",
    "    \"\"\"Store result\"\"\"\n",
    "    tf_matrix, term_indices, indices_term, doc_indices, doc_names = load_data('data/courses.txt')\n",
    "    tfidf_matrix = tf_idf(tf_matrix, doc_indices, term_indices)\n",
    "    save_sparse_csr(\"tf_matrix\", tf_matrix)\n",
    "    save_sparse_csr(\"tfidf_matrix\", tfidf_matrix)\n",
    "    save_json([term_indices], 'term_indices.txt')\n",
    "    save_json([indices_term], 'indices_term.txt')\n",
    "    save_json([doc_indices], 'doc_indices.txt')\n",
    "    save_json([doc_names], 'doc_names.txt')\n",
    "store_result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15 terms  of the IX class with the highest TF-IDF scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 15 (descending) terms of COM-308 class: \n",
      "mining\n",
      "service\n",
      "online\n",
      "social\n",
      "explore\n",
      "world\n",
      "hadoop\n",
      "real\n",
      "recommender\n",
      "auction\n",
      "commerce\n",
      "retrieval\n",
      "datasets\n",
      "internet\n",
      "analytics\n"
     ]
    }
   ],
   "source": [
    "def top_highest_score(class_name, n):\n",
    "    tf_matrix, term_indices, indices_term, doc_indices, doc_names = load_data('data/courses.txt')\n",
    "    tfidf_matrix = tf_idf(tf_matrix, doc_indices, term_indices)\n",
    "    \n",
    "    cols = tfidf_matrix.getcol(doc_indices[class_name])\n",
    "    data = cols.data\n",
    "    row_indices = cols.toarray().nonzero()[0]\n",
    "    #col_indices = cols.toarray().nonzero()[1] # Not interested in\n",
    "    \n",
    "    indices = data.argsort()[::-1][:n]\n",
    "    top_values = data[indices]\n",
    "    top_indices = row_indices[indices]\n",
    "    \n",
    "    print(\"Top {k} (descending) terms of {c} class: \".format(k=n, c=class_name))\n",
    "    for i in top_indices:\n",
    "        print (indices_term[i])\n",
    "    \n",
    "top_highest_score(\"COM-308\", 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Difference between the large scores and the small ones: term 'mining' has a high frequency on this document AND is contained in a few documents => mining is a keyword important of this document. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4.3: Document similarity search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"https://en.wikipedia.org/wiki/Okapi_BM25\"\"\"\n",
    "\n",
    "def bm25_score(tf_matrix, row, col, avg_doc_lenght, nbDocs, doc_length, K, B):\n",
    "    tf  = tf_matrix[row, col]\n",
    "    \"\"\"term_length : # of doc contain 'term'\"\"\"\n",
    "    term_length = tf_matrix.getrow(row).nnz\n",
    "    idf = math.log((nbDocs - term_length + 0.5)/(term_length + 0.5))\n",
    "    return idf * (tf * (K + 1)) / (tf + K*(1 - B + (B * doc_length / avg_doc_lenght)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def top_bm25_similarity(query, n):\n",
    "    K = 1.5\n",
    "    B = .75\n",
    "    \"\"\"a dict for storing result. E.g.: scores[CS-308] = 14\"\"\"\n",
    "    scores = {}\n",
    "    tf_matrix, term_indices, indices_term, doc_indices, doc_names = load_data('data/courses.txt')\n",
    "        \n",
    "    \"\"\"Number of documents\"\"\"\n",
    "    nbDocs = len(doc_indices)\n",
    "    \n",
    "    \"\"\"Average document length\"\"\"\n",
    "    avg_doc_lenght = 0.0\n",
    "    for doc in doc_indices.keys():\n",
    "        avg_doc_lenght += tf_matrix.getcol(doc_indices[doc]).nnz\n",
    "    avg_doc_lenght /= nbDocs\n",
    "\n",
    "    \"\"\"Compute score (query, doc)\"\"\"\n",
    "    processed = preprocessing(query)\n",
    "    for doc in doc_indices.keys():\n",
    "        col = doc_indices[doc]\n",
    "        \"\"\"Length of document 'doc'\"\"\"\n",
    "        doc_length = tf_matrix.getcol(col).nnz\n",
    "        score = 0.0\n",
    "        for term in processed:\n",
    "            row = term_indices.get(term)\n",
    "            # Check if term exist\n",
    "            if row != None:\n",
    "                score += bm25_score(tf_matrix, row, col, avg_doc_lenght, nbDocs, doc_length, K, B)\n",
    "        scores[doc] = score\n",
    "        \n",
    "    \"\"\"Sort dict by value/score and take n\"\"\"\n",
    "    sorted_scores = sorted(scores.items(), key=operator.itemgetter(1), reverse=True)[:n]\n",
    "    \n",
    "    print(\"Top {k} classes (descending) for your query '{q}'\".format(k=n,q=query))\n",
    "    for (k,v) in sorted_scores:\n",
    "        print(\"{key}--{c} with score {s}\".format(key=k, c=doc_names[k],s=v))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 classes (descending) for your query 'markov chains'\n",
      "MATH-332--Applied stochastic processes with score 7.438899485691768\n",
      "COM-516--Markov chains and algorithmic applications with score 5.528111584837584\n",
      "MGT-484--Applied probability & stochastic processes with score 5.268466618583339\n",
      "EE-605--Statistical Sequence Processing with score 3.9862647912865166\n",
      "MGT-528--Operations: economics & strategy with score 3.2625344882425895\n"
     ]
    }
   ],
   "source": [
    "top_bm25_similarity(\"markov chains\", 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 classes (descending) for your query 'facebook'\n",
      "EE-727--Computational Social Media with score 1.223114375979703\n",
      "MGT-641(b)--Technology and Public Policy - (b) Technology, policy and regulation with score 0.0\n",
      "MSE-231--Ceramics, structures and properties   TP with score 0.0\n",
      "PHYS-458--Metrology I with score 0.0\n",
      "FIN-504--Credit risk with score 0.0\n"
     ]
    }
   ],
   "source": [
    "top_bm25_similarity(\"facebook\", 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explain the result obtained: \n",
    "\n",
    "For the 'markov chains': the result is plausible, all docs returned contain either 'markov' or 'chains' or 'markov chains'\n",
    "\n",
    "For the 'facebook': the only document that contains term 'facebook' is EE-727 in which is returned without doubt. But now we have a problem because the algorithm does not know which document are related with the query 'facebook' if it does not contain 'facebook'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A B C'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(['A', 'B', 'C'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
