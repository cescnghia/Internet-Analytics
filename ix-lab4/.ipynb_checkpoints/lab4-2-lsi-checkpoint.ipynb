{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text 2: Latent semantic indexing\n",
    "**Internet Analytics - Lab 4**\n",
    "\n",
    "---\n",
    "\n",
    "**Group:** *N*\n",
    "\n",
    "**Names:**\n",
    "\n",
    "* *Anh Nghia Khau (223613)*\n",
    "* *Sandra Djambazovska(224638)*\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "#### Instructions\n",
    "\n",
    "*This is a template for part 2 of the lab. Clearly write your answers, comments and interpretations in Markodown cells. Don't forget that you can add $\\LaTeX$ equations in these cells. Feel free to add or remove any cell.*\n",
    "\n",
    "*Please properly comment your code. Code readability will be considered for grading. To avoid long cells of codes in the notebook, you can also embed long python functions and classes in a separate module. Don’t forget to hand in your module if that is the case. In multiple exercises, you are required to come up with your own method to solve various problems. Be creative and clearly motivate and explain your methods. Creativity and clarity will be considered for grading.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import math\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.sparse import csr_matrix\n",
    "from utils import load_json, load_pkl\n",
    "import operator\n",
    "from scipy.sparse.linalg import svds\n",
    "\n",
    "import nltk\n",
    "from nltk import pos_tag\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize, RegexpTokenizer\n",
    "from nltk.corpus import wordnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_words(word):\n",
    "    \"\"\"Transform HelloWord into Hello Word\"\"\"\n",
    "    if (word.isupper() or word.islower()):\n",
    "        return word\n",
    "    else:\n",
    "        pos_to_cut = []\n",
    "        for i in range(1, len(word)):\n",
    "            if (word[i].isupper()):\n",
    "                pos_to_cut.append(i)\n",
    "        curr = 0\n",
    "        words = ''\n",
    "        for pos in pos_to_cut:\n",
    "            words += ' ' + word[curr: pos]\n",
    "            curr = pos\n",
    "        words += ' ' + word[curr:]\n",
    "        return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Combine RegularExpr (Remove the punctuation) and word_tokenize\"\"\"\n",
    "def tokenization(sentence):\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    temp = ''\n",
    "    for w in sentence.split():\n",
    "        temp += ' ' + split_words(w)   \n",
    "    temp = word_tokenize(temp)\n",
    "    new_sentence = ''\n",
    "    for grams in temp:\n",
    "        new_sentence += ' ' + grams\n",
    "\n",
    "    return  tokenizer.tokenize(new_sentence) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def stop_words(sentence):\n",
    "    stopwords = load_pkl('data/stopwords.pkl')\n",
    "    return [x.lower() for x in sentence if x.lower() not in stopwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_wordnet_pos(treebank_tag):\n",
    "    \"\"\"Map ['NN', 'NNS', 'NNP', 'NNPS'] to NOUN.....\"\"\"\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lemmatization(sentence):\n",
    "    lemmatiser = WordNetLemmatizer()\n",
    "    tokens_pos = pos_tag(sentence)\n",
    "    tokens_pos = [(w,get_wordnet_pos(p)) for (w,p) in tokens_pos]\n",
    "    \n",
    "    return [lemmatiser.lemmatize(w, pos=p) for (w,p) in tokens_pos if p != None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocessing(sentence):\n",
    "    \"\"\"Tokenization\"\"\"\n",
    "    new_sentence = tokenization(sentence)\n",
    "    \"\"\"Stopwords\"\"\"\n",
    "    new_sentence = stop_words(new_sentence)\n",
    "    \"\"\"POS and Lemmatization\"\"\"\n",
    "    new_sentence = lemmatization(new_sentence)\n",
    "    \n",
    "    return new_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data from previous exercice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_sparse_csr(filename):\n",
    "    loader = np.load(filename)\n",
    "    return csr_matrix((  loader['data'], loader['indices'], loader['indptr']),\n",
    "                         shape = loader['shape'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    tf_matrix    = load_sparse_csr(\"tf_matrix.npz\")\n",
    "    tfidf_matrix = load_sparse_csr(\"tfidf_matrix.npz\")\n",
    "    doc_indices  = load_json('doc_indices.txt')[0]\n",
    "    term_indices = load_json('term_indices.txt')[0]\n",
    "    indices_term = load_json('indices_term.txt')[0]\n",
    "    doc_names    = load_json('doc_names.txt')[0]\n",
    "    \n",
    "    return tf_matrix, tfidf_matrix, doc_indices, term_indices, indices_term, doc_names "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4.4: Latent semantic indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here X is not a square matrix, I would suppose that we take the singular values of X\n",
    "\n",
    "The singular values of a m×n matrix A are the positive square roots of the nonzero eigenvalues of the corresponding matrix (A.T @ A). The corresponding eigenvectors are called the singular vectors.\n",
    "\n",
    "U is an M x K matrix: a row i of U means term i is decomposed into K-latents concept instead of N documents (coordinate of term in latent space)\n",
    "\n",
    "V is an N x K matrix: a row i of V means document i is decomposed into K-latents concept instead of M terms documents (coordinate of document in latent space)\n",
    "\n",
    "S is a K x K diagonal matrix: the first value of S (biggest on top left) is the first 'topic' in which coresspond to the first column of U and the first column of v\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def LSI(path, K):\n",
    "    tf_matrix, tfidf_matrix, doc_indices, term_indices, indices_term, doc_names = load_data()\n",
    "    U, S, V_T = svds(tfidf_matrix, k=K)\n",
    "    return (S[::-1][:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 eigenvalues of X\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 38.36486966,  27.26559776,  24.77872325,  23.16109916,\n",
       "        22.96221797,  22.11653527,  21.57938508,  20.86047732,\n",
       "        20.34718015,  20.21306309,  19.90632062,  19.88701028,\n",
       "        19.49484284,  18.96126007,  18.70856149,  18.28396281,\n",
       "        18.15410327,  18.04668982,  17.85978557,  17.78966251])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Top 20 eigenvalues of X\")\n",
    "LSI('data/courses.txt', 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4.5: Topic extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-10 topics as a combinations of terms: \n",
      "   Topic 0:\n",
      "     'seminar'\n",
      "     'numerical'\n",
      "     'brain'\n",
      "     'convex'\n",
      "     'measurement'\n",
      "     'stellar'\n",
      "     'electrochemical'\n",
      "     'talk'\n",
      "     'star'\n",
      "     'econometric'\n",
      "     'visualization'\n",
      "     'magnetic'\n",
      "     'series'\n",
      "     'cognitive'\n",
      "     'plasma'\n",
      "   Topic 1:\n",
      "     'atmospheric'\n",
      "     'film'\n",
      "     'turbulent'\n",
      "     'thin'\n",
      "     'solidification'\n",
      "     'econometric'\n",
      "     'acoustic'\n",
      "     'stain'\n",
      "     'plasma'\n",
      "     'fluid'\n",
      "     'boundary'\n",
      "     'layer'\n",
      "     'additive'\n",
      "     'exchange'\n",
      "     'transport'\n",
      "   Topic 2:\n",
      "     'telomerase'\n",
      "     'telomere'\n",
      "     'telomeres'\n",
      "     'rapid'\n",
      "     'image'\n",
      "     'senescence'\n",
      "     'additive'\n",
      "     'gene'\n",
      "     'stain'\n",
      "     'test'\n",
      "     'film'\n",
      "     'assay'\n",
      "     'dna'\n",
      "     'thin'\n",
      "     'seminar'\n",
      "   Topic 3:\n",
      "     'ccd'\n",
      "     'communication'\n",
      "     'photodiodes'\n",
      "     'laser'\n",
      "     'plasma'\n",
      "     'brain'\n",
      "     'mems'\n",
      "     'sensor'\n",
      "     'label'\n",
      "     'synthesis'\n",
      "     'detector'\n",
      "     'neuroprostheses'\n",
      "     'cancer'\n",
      "     'organizational'\n",
      "     'mem'\n",
      "   Topic 4:\n",
      "     'nanophysics'\n",
      "     'condense'\n",
      "     'crucial'\n",
      "     'magnetic'\n",
      "     'front'\n",
      "     'edge'\n",
      "     'supply'\n",
      "     'tumor'\n",
      "     'cut'\n",
      "     'cancer'\n",
      "     'expose'\n",
      "     'experimental'\n",
      "     'nlp'\n",
      "     'game'\n",
      "     'stellar'\n",
      "   Topic 5:\n",
      "     'philosophical'\n",
      "     'artist'\n",
      "     'sensor'\n",
      "     'circuit'\n",
      "     'visualization'\n",
      "     'stain'\n",
      "     'laser'\n",
      "     'hematoxylin'\n",
      "     'praxis'\n",
      "     'scale'\n",
      "     'optic'\n",
      "     'philosophy'\n",
      "     'safety'\n",
      "     'telomerase'\n",
      "     'telomere'\n",
      "   Topic 6:\n",
      "     'image'\n",
      "     'risk'\n",
      "     'analog'\n",
      "     'magnetic'\n",
      "     'mem'\n",
      "     'mems'\n",
      "     'numerical'\n",
      "     'week'\n",
      "     'gate'\n",
      "     'geometry'\n",
      "     'equilibrium'\n",
      "     'philosophical'\n",
      "     'case'\n",
      "     'plasma'\n",
      "     'mixed'\n",
      "   Topic 7:\n",
      "     'humanitarianism'\n",
      "     'health'\n",
      "     'risk'\n",
      "     'cancer'\n",
      "     'tumor'\n",
      "     'plasma'\n",
      "     'tissue'\n",
      "     'nanophysics'\n",
      "     'atmospheric'\n",
      "     'mems'\n",
      "     'actor'\n",
      "     'governmental'\n",
      "     'condense'\n",
      "     'stain'\n",
      "     'electrochemical'\n",
      "   Topic 8:\n",
      "     'optimization'\n",
      "     'semiconductor'\n",
      "     'graph'\n",
      "     'communication'\n",
      "     'protein'\n",
      "     'ccd'\n",
      "     'corporate'\n",
      "     'stain'\n",
      "     'puzzle'\n",
      "     'numerical'\n",
      "     'organic'\n",
      "     'analog'\n",
      "     'optic'\n",
      "     'convex'\n",
      "     'hematoxylin'\n",
      "   Topic 9:\n",
      "     'telomerase'\n",
      "     'telomere'\n",
      "     'cancer'\n",
      "     'tumor'\n",
      "     'nanophysics'\n",
      "     'game'\n",
      "     'empirical'\n",
      "     'supply'\n",
      "     'econometric'\n",
      "     'equilibrium'\n",
      "     'seminar'\n",
      "     'competition'\n",
      "     'telomeres'\n",
      "     'cognitive'\n",
      "     'business'\n"
     ]
    }
   ],
   "source": [
    "def topic_extraction_terms(nbTopics, n_terms):\n",
    "    tf_matrix, tfidf_matrix, doc_indices, term_indices, indices_term, doc_names = load_data()\n",
    "\n",
    "    \"\"\"low-rank approximation\"\"\"\n",
    "    U, S, V_T = svds(tfidf_matrix, 60) #60\n",
    "    \n",
    "    print(\"Top-{k} topics as a combinations of terms: \".format(k=nbTopics))\n",
    "    for i in range (nbTopics):\n",
    "        print(\"   Topic \" + str(i) + \":\")\n",
    "        abs_score = [np.abs(x) for x in U[:,i]]\n",
    "        top_terms = np.argsort(abs_score)[::-1][:n_terms]\n",
    "        for y in top_terms:\n",
    "            print(\"     '{k}'\".format(k=indices_term.get(str(y))))\n",
    "\n",
    "topic_extraction_terms(nbTopics=10, n_terms=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "T0: security, T1: life science, T2: biology, T3: biomedical engineering ?, T4:  ??? , T5: ???, T6: ???, T7: ?, T8: electrical engineering ? ,T9: ?\n",
    "\n",
    "=> difficult to recognise !!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-10 topics as a combinations of documents: \n",
      "Topic 0:\n",
      "   'CS-487-Industrial automation'\n",
      "   'ENG-421-Fundamentals in Systems Engineering'\n",
      "   'CIVIL-428-Engineering geology for geo-energy'\n",
      "   'CIVIL-402-Geomechanics'\n",
      "   'CIVIL-444-Energy geostructures'\n",
      "   'COM-401-Cryptography and security'\n",
      "   'CIVIL-709-New Concretes for Structures'\n",
      "   'PENS-201-Making structural logic'\n",
      "   'COM-501-Advanced cryptography'\n",
      "   'CH-432-Structure and reactivity'\n",
      "   'CIVIL-429-Reservoir mechanics for geo-energy and the environment'\n",
      "   'MSE-465-Thin film fabrication processes'\n",
      "   'MSE-802-CCMX Summer School - Multiscale Modelling of Materials (2016)'\n",
      "   'CS-206-Parallelism and concurrency'\n",
      "   'CS-401-Applied data analysis'\n",
      "Topic 1:\n",
      "   'CH-415-Chemistry of small biological molecules'\n",
      "   'CIVIL-402-Geomechanics'\n",
      "   'MSE-651-Crystallography of structural phase transformations'\n",
      "   'ENG-627-Academic Writing for Doctoral Students'\n",
      "   'ENV-719-Localization and Navigation Methods'\n",
      "   'CIVIL-444-Energy geostructures'\n",
      "   'COM-401-Cryptography and security'\n",
      "   'CH-413-Nanobiotechnology and biophysics'\n",
      "   'CIVIL-428-Engineering geology for geo-energy'\n",
      "   'COM-501-Advanced cryptography'\n",
      "   'BIO-714-Mechanisms of cell motility'\n",
      "   'MGT-409-D. Thinking: real problems, human-focused solutions'\n",
      "   'CH-447-Advanced materials for photovoltaics and lighting'\n",
      "   'BIOENG-801-Summer school on healthcare diagnostics'\n",
      "   'AR-402(v)-Théorie et critique du projet MA2 (Boltshauser)'\n",
      "Topic 2:\n",
      "   'AR-402(v)-Théorie et critique du projet MA2 (Boltshauser)'\n",
      "   'MGT-404-Principles of intellectual property management'\n",
      "   'FIN-609-Asset Pricing'\n",
      "   'EE-565-Industrial electronics II'\n",
      "   'CS-431-Introduction to natural language processing'\n",
      "   'BIOENG-801-Summer school on healthcare diagnostics'\n",
      "   'PHYS-709-Stellar evolution and nucleosynthesis (UNIGe)'\n",
      "   'ChE-601(a)-Leading research in Chemical Engineering (a)'\n",
      "   'ChE-601(b)-Leading research in Chemical Engineering (b)'\n",
      "   'EE-532-Integrated circuits technology'\n",
      "   'HUM-427(a)-History of globalization I'\n",
      "   'CH-432-Structure and reactivity'\n",
      "   'MGT-409-D. Thinking: real problems, human-focused solutions'\n",
      "   'BIO-465-Biological modeling of neural networks'\n",
      "   'BIOENG-430-Introduction to cellular and molecular biotechnology'\n",
      "Topic 3:\n",
      "   'MSE-610-Non-destructive evaluation methods'\n",
      "   'CH-415-Chemistry of small biological molecules'\n",
      "   'MSE-657-CCMX Winter School - Additive Manufacturing of Metals and the Material Science Behind It''\n",
      "   'MSE-652-Introduction to scanning electron microscopy microanalysis techniques'\n",
      "   'ENV-715-Atmospheric Boundary Layer'\n",
      "   'ME-481-Biomechanics of the cardiovascular system'\n",
      "   'ME-425-Model predictive control'\n",
      "   'ME-460-Renewable energy (for ME)'\n",
      "   'BIO-714-Mechanisms of cell motility'\n",
      "   'CS-435-Analytic algorithms'\n",
      "   'CS-487-Industrial automation'\n",
      "   'HUM-316-Cognitive psychology B'\n",
      "   'COM-501-Advanced cryptography'\n",
      "   'ME-454-Modelling and optimization of energy systems'\n",
      "   'CH-432-Structure and reactivity'\n",
      "Topic 4:\n",
      "   'MSE-465-Thin film fabrication processes'\n",
      "   'EE-565-Industrial electronics II'\n",
      "   'EE-532-Integrated circuits technology'\n",
      "   'ENV-719-Localization and Navigation Methods'\n",
      "   'CIVIL-428-Engineering geology for geo-energy'\n",
      "   'PHYS-630-Advanced experimental methods in condensed matter and nanophysics'\n",
      "   'PHYS-310-Solid state physics II'\n",
      "   'PHYS-627-Magnetic and semiconducting nanostructures'\n",
      "   'MGT-409-D. Thinking: real problems, human-focused solutions'\n",
      "   'MGT-625-Readings in Organization Economics'\n",
      "   'MSE-657-CCMX Winter School - Additive Manufacturing of Metals and the Material Science Behind It''\n",
      "   'PHYS-734-Tokamak Plasma Control'\n",
      "   'ENG-615-Topics in Autonomous Robotics'\n",
      "   'HUM-427(a)-History of globalization I'\n",
      "   'ME-481-Biomechanics of the cardiovascular system'\n",
      "Topic 5:\n",
      "   'CS-431-Introduction to natural language processing'\n",
      "   'EE-565-Industrial electronics II'\n",
      "   'ENV-719-Localization and Navigation Methods'\n",
      "   'ENG-627-Academic Writing for Doctoral Students'\n",
      "   'MSE-610-Non-destructive evaluation methods'\n",
      "   'CH-413-Nanobiotechnology and biophysics'\n",
      "   'CS-401-Applied data analysis'\n",
      "   'ENG-615-Topics in Autonomous Robotics'\n",
      "   'CIVIL-449-Non linear analysis of structures'\n",
      "   'ME-415-Methods for rapid production and development'\n",
      "   'ENV-167-Introduction to environmental engineering'\n",
      "   'BIO-609-Practical - Bucher Lab'\n",
      "   'MSE-646-CCMX Winter School - Metal Science'\n",
      "   'BIO-622-Practical - Lingner Lab'\n",
      "   'MGT-404-Principles of intellectual property management'\n",
      "Topic 6:\n",
      "   'PHYS-630-Advanced experimental methods in condensed matter and nanophysics'\n",
      "   'MGT-409-D. Thinking: real problems, human-focused solutions'\n",
      "   'CS-487-Industrial automation'\n",
      "   'BIO-488-Scientific project design in translational oncology'\n",
      "   'MICRO-711-RF MEMS for communications applications'\n",
      "   'BIOENG-513-Lab methods : biosafety'\n",
      "   'ChE-601(a)-Leading research in Chemical Engineering (a)'\n",
      "   'ChE-601(b)-Leading research in Chemical Engineering (b)'\n",
      "   'PHYS-310-Solid state physics II'\n",
      "   'MGT-625-Readings in Organization Economics'\n",
      "   'MGT-454-Principles of microeconomics'\n",
      "   'FIN-612-Empirical Methods in Corporate Finance'\n",
      "   'PHYS-709-Stellar evolution and nucleosynthesis (UNIGe)'\n",
      "   'BIO-611-Practical - Constam Lab'\n",
      "   'BIO-463-Genomics and bioinformatics'\n",
      "Topic 7:\n",
      "   'CS-431-Introduction to natural language processing'\n",
      "   'MSE-802-CCMX Summer School - Multiscale Modelling of Materials (2016)'\n",
      "   'CH-432-Structure and reactivity'\n",
      "   'CH-406-Analysis of ancient materials and their degradation'\n",
      "   'PHYS-709-Stellar evolution and nucleosynthesis (UNIGe)'\n",
      "   'EE-613-Machine Learning for Engineers'\n",
      "   'MSE-610-Non-destructive evaluation methods'\n",
      "   'CH-700(2)-Advanced electroanalytical chemistry (II session)'\n",
      "   'MICRO-530-Nanotechnology'\n",
      "   'PHYS-622-Principles and Practicals in X-Ray Scattering'\n",
      "   'ME-481-Biomechanics of the cardiovascular system'\n",
      "   'MATH-457-Numerical approximation of PDE's II'\n",
      "   'CS-487-Industrial automation'\n",
      "   'PHYS-630-Advanced experimental methods in condensed matter and nanophysics'\n",
      "   'PHYS-424-Plasma physics III'\n",
      "Topic 8:\n",
      "   'MICRO-711-RF MEMS for communications applications'\n",
      "   'MSE-610-Non-destructive evaluation methods'\n",
      "   'CH-406-Analysis of ancient materials and their degradation'\n",
      "   'CH-704-Computation of molecular properties'\n",
      "   'PHYS-627-Magnetic and semiconducting nanostructures'\n",
      "   'MICRO-523-Optical detectors'\n",
      "   'CS-431-Introduction to natural language processing'\n",
      "   'BIOENG-513-Lab methods : biosafety'\n",
      "   'MATH-457-Numerical approximation of PDE's II'\n",
      "   'HUM-417(b)-Philosophy, epistemology and history of science II'\n",
      "   'EE-606-Nanocomputing: Devices, Circuits and Architectures'\n",
      "   'CH-700(2)-Advanced electroanalytical chemistry (II session)'\n",
      "   'HUM-417(a)-Philosophy, epistemology and history of science I'\n",
      "   'MSE-646-CCMX Winter School - Metal Science'\n",
      "   'MICRO-530-Nanotechnology'\n",
      "Topic 9:\n",
      "   'CS-431-Introduction to natural language processing'\n",
      "   'EE-565-Industrial electronics II'\n",
      "   'HUM-429(a)-Philosophy of life sciences I'\n",
      "   'AR-522-Difficult Double Double Histories'\n",
      "   'CH-432-Structure and reactivity'\n",
      "   'MICRO-530-Nanotechnology'\n",
      "   'BIO-622-Practical - Lingner Lab'\n",
      "   'PHYS-627-Magnetic and semiconducting nanostructures'\n",
      "   'MSE-465-Thin film fabrication processes'\n",
      "   'MICRO-711-RF MEMS for communications applications'\n",
      "   'AR-402(y)-Théorie et critique du projet MA2 (Huang)'\n",
      "   'ME-415-Methods for rapid production and development'\n",
      "   'MSE-802-CCMX Summer School - Multiscale Modelling of Materials (2016)'\n",
      "   'ENG-603-Solid state image sensing'\n",
      "   'HUM-417(a)-Philosophy, epistemology and history of science I'\n"
     ]
    }
   ],
   "source": [
    "def topic_extraction_docs(nbTopics, n_docs):\n",
    "    tf_matrix, tfidf_matrix, doc_indices, term_indices, indices_term, doc_names = load_data()\n",
    "\n",
    "    \"\"\"Create a mapping between col and course's name\"\"\"\n",
    "    indices_doc = dict((v,k) for k,v in doc_indices.items())\n",
    "\n",
    "    \"\"\"low-rank approximation\"\"\"\n",
    "    U, S, V_T = svds(tfidf_matrix, 80)\n",
    "    \n",
    "    print(\"Top-{k} topics as a combinations of documents: \".format(k=nbTopics))\n",
    "    for i in range (nbTopics):\n",
    "        print(\"Topic \" + str(i) + \":\")\n",
    "        abs_score = [np.abs(x) for x in V_T.T[:,i]]\n",
    "        top_docs = np.argsort(abs_score)[::-1][:n_docs]\n",
    "        for y in top_docs:\n",
    "            print(\"   '{k}-{s}'\".format(k=indices_doc.get(y),s=doc_names[indices_doc[y]]))\n",
    "\n",
    "topic_extraction_docs(nbTopics=10, n_docs=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "T0: Civil engineering ? T1: ???, T2: ???, T3: ???, T4: ??? , T5: ???, T6: ???, T7: ???, T8: ??? ,T9: ???\n",
    "\n",
    "=> difficult to recognise !!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4.6: Document similarity search in concept-space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def similarity(u, S, v_t):\n",
    "    temp = np.diag(S) @ v_t\n",
    "    return np.dot(u, temp) / np.sqrt(np.sum(u ** 2) * np.sum(temp **2)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def search(query, n):\n",
    "    nbTopics = 35\n",
    "    \"\"\"a dict for storing result. E.g.: scores[CS-308] = 14\"\"\"\n",
    "    scores = {}\n",
    "    \n",
    "    tf_matrix, tfidf_matrix, doc_indices, term_indices, indices_term, doc_names = load_data()\n",
    "    \"\"\"Create a mapping between col and course's name\"\"\"\n",
    "    indices_doc = dict((v,k) for k,v in doc_indices.items())\n",
    "\n",
    "    \"\"\"low-rank approximation\"\"\"\n",
    "    U, S, V_T = svds(tfidf_matrix, nbTopics)\n",
    "    \n",
    "    \"\"\"Pre-processing query\"\"\"\n",
    "    processed = preprocessing(query)\n",
    "    \n",
    "    \"\"\"Compute score of 'query' for each doc\"\"\"\n",
    "    for doc in doc_indices.keys():\n",
    "        \"Take the index of doc's column\"\n",
    "        col = doc_indices[doc]\n",
    "        score = 0.0\n",
    "        \"For each term in the query\"\n",
    "        for term in processed:\n",
    "            row = term_indices.get(term)\n",
    "            \"If term doesn't exist => continue\"\n",
    "            if row == None:\n",
    "                continue\n",
    "            u = U[row] # term u\n",
    "            v_t = V_T.T[col] # doc v\n",
    "            score += similarity(u, S, v_t)\n",
    "        scores[doc] = score\n",
    "    \n",
    "    \"\"\"Sort dict by value/score and take n\"\"\"\n",
    "    sorted_scores = sorted(scores.items(), key=operator.itemgetter(1), reverse=True)[:n]\n",
    "    \n",
    "    print(\"Top {k} classes (descending) for your query '{q}'\".format(k=n,q=query))\n",
    "    for (k,v) in sorted_scores:\n",
    "        print(\"{key}--{c} with score {s}\".format(key=k, c=doc_names[k],s=v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 classes (descending) for your query 'facebook'\n",
      "EE-727--Computational Social Media with score 0.9047365692929483\n",
      "COM-308--Internet analytics with score 0.6085845559101029\n",
      "CS-423--Distributed information systems with score 0.5897271271506194\n",
      "EE-593--Social media with score 0.5548492126267299\n",
      "COM-208--Computer networks with score 0.5488574990330605\n"
     ]
    }
   ],
   "source": [
    "search('facebook', 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Very good, this time it returns some classes 'social media' or 'social network'. The algorithm now know the 'relationship' between these documents !!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 classes (descending) for your query 'markov chains'\n",
      "MATH-332--Applied stochastic processes with score 1.3867736168516411\n",
      "MGT-484--Applied probability & stochastic processes with score 1.36451454007995\n",
      "COM-516--Markov chains and algorithmic applications with score 1.2685938880684826\n",
      "COM-512--Networks out of control with score 1.158170215991472\n",
      "FIN-600--Game Theory with score 1.1132292998035345\n"
     ]
    }
   ],
   "source": [
    "search('markov chains', 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4.7: Document-document similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"https://en.wikipedia.org/wiki/Latent_semantic_analysis\"\"\"\n",
    "\"\"\"\"\"\"\n",
    "def doc_similarity(doc1, doc2, S):\n",
    "    doc1_ = np.diag(S) @ doc1\n",
    "    doc2_ = np.diag(S) @ doc2 \n",
    "    return np.dot(doc1_, doc2_) / np.sqrt(np.sum(doc1_ ** 2) * np.sum(doc2_ ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def most_similar(course, n):\n",
    "    nbTopics = 35\n",
    "    \"\"\"a dict for storing result. E.g.: scores[class] = 14\n",
    "       means that similarity between (course, class) = 14\"\"\"\n",
    "    scores = {}\n",
    "\n",
    "    tf_matrix, tfidf_matrix, doc_indices, term_indices, indices_term, doc_names = load_data()\n",
    "    \n",
    "    \"\"\"low-rank approximation\"\"\"\n",
    "    U, S, V_T = svds(tfidf_matrix, nbTopics)\n",
    "    \n",
    "    col1 = doc_indices[course]\n",
    "    \"\"\"Compute score of 'query' for each doc\"\"\"\n",
    "    for doc in doc_indices.keys():      \n",
    "        col2 = doc_indices[doc]\n",
    "        doc1 = V_T.T[col1]\n",
    "        doc2 = V_T.T[col2]\n",
    "        scores[doc] = doc_similarity(doc1, doc2, S)\n",
    "    \n",
    "    \"\"\"Sort dict by value/score and take n\"\"\"\n",
    "    sorted_scores = sorted(scores.items(), key=operator.itemgetter(1), reverse=True)[:n+1]\n",
    "    \n",
    "    print(\"Top {k} classes (descending) most similar to '{q}'\".format(k=n,q=course))\n",
    "    for (k,v) in sorted_scores:\n",
    "        if (k == course):\n",
    "            continue\n",
    "        print(\"{key}--{c} with score {s}\".format(key=k, c=doc_names[k],s=v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 classes (descending) most similar to 'COM-308'\n",
      "CS-423--Distributed information systems with score 0.8504745986824664\n",
      "EE-558--A Network Tour of Data Science with score 0.8266593814062848\n",
      "COM-208--Computer networks with score 0.7804548717769448\n",
      "COM-407--TCP/IP networking with score 0.7765591647293033\n",
      "COM-512--Networks out of control with score 0.7582265717362375\n"
     ]
    }
   ],
   "source": [
    "most_similar('COM-308', 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
